{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from keras.models import *\n",
    "from keras.models import load_model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ead86ac289c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def label_to_code(label_img):\n",
    "    row, column, channels = label_img.shape\n",
    "    for i in range(row):\n",
    "        for j in range(column):\n",
    "            if label_img[i, j, 0] >= 0.75:\n",
    "                label_img[i, j, :] = [1, 0, 0]\n",
    "            elif (label_img[i, j, 0] < 0.75) & (label_img[i, j, 0] >= 0.5):\n",
    "                label_img[i, j, :] = [0, 1, 0]\n",
    "            elif (label_img[i, j, 0] < 0.5) & (label_img[i, j, 0] >= 0.25):\n",
    "                label_img[i, j, :] = [0, 0, 1]\n",
    "    return label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c40f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "# data_root：读取图像的根目录，要求数据集格式和结构如当前数据集所示\n",
    "# data_type：读取文件类型，取值分别为：“train”训练集、“val”验证集、“test”测试集\n",
    "# need_name_list：是否返回结果列表，测试集需要返回结果列表\n",
    "# need_enhanced:是否进行数据增强，默认为False，不进行\n",
    "def load_image(data_root, data_type, size=None, need_name_list=False):\n",
    "    image_path = os.path.join(data_root, data_type, \"image\")\n",
    "    label_path = os.path.join(data_root, data_type, \"label\")\n",
    "\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    image_name_list = []\n",
    "\n",
    "    for file in os.listdir(image_path):\n",
    "        image_file = os.path.join(image_path, file)\n",
    "        label_file_name = file.split(\".\")[0]+\"_gt.png\"\n",
    "        label_file = os.path.join(label_path, label_file_name)\n",
    "        if need_name_list is True:\n",
    "            image_name_list.append(file)\n",
    "        img = cv2.imread(image_file)\n",
    "        label = cv2.imread(label_file)\n",
    "        if size is not None:\n",
    "            row, column, channel = size\n",
    "            img = cv2.resize(img, (column, row, channel))\n",
    "            label = cv2.resize(label, (column, row, channel))\n",
    "        img = img / 255\n",
    "        label = label / 255\n",
    "        image_list.append(img)\n",
    "        label = label_to_code(label)  # 对标签进行编码\n",
    "        label_list.append(label)\n",
    "\n",
    "    if need_name_list is True:\n",
    "        return np.array(image_list), np.array(label_list), image_name_list\n",
    "    else:\n",
    "        return np.array(image_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8e5b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape:  (200, 224, 224, 3) (200, 224, 224, 3)\n",
      "val set shape:  (40, 224, 224, 3) (40, 224, 224, 3)\n",
      "test set shape:  (40, 224, 224, 3) (40, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./dataset\"\n",
    "train_data, train_label = load_image(data_path, \"train\")  # train set\n",
    "print(\"train set shape: \", train_data.shape, train_label.shape)\n",
    "val_data, val_label = load_image(data_path, \"val\")        # val set\n",
    "print(\"val set shape: \", val_data.shape, val_label.shape)\n",
    "test_data, test_label = load_image(data_path, \"test\")     # test set\n",
    "print(\"test set shape: \", test_data.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b1ddb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################损失函数\n",
    "def dice_coefficient(y_true, y_pred, smooth=0.0000000001):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return 1-dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice_coff(label, predict):\n",
    "    return np.sum(2*label*predict)/(np.sum(label)+np.sum(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73b05524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 224, 224, 32) 896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 224, 224, 32) 9248        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 112, 112, 32) 0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 112, 112, 64) 18496       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 56, 56, 64)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 56, 56, 128)  73856       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 28, 28, 128)  0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 28, 28, 256)  295168      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 28, 28, 256)  0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 14, 14, 256)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 512)  1180160     max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 14, 14, 512)  2359808     conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 14, 14, 512)  0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 28, 28, 512)  0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 28, 28, 256)  524544      up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 28, 28, 512)  0           dropout_5[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 28, 28, 256)  1179904     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 56, 56, 256)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 56, 56, 128)  131200      up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 56, 56, 256)  0           conv2d_52[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 56, 56, 128)  295040      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 112, 112, 128 0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 112, 112, 64) 32832       up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 112, 112, 128 0           conv2d_50[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 112, 112, 64) 73792       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 224, 224, 64) 0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 224, 224, 32) 8224        up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 224, 224, 64) 0           conv2d_48[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 224, 224, 32) 18464       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 224, 224, 32) 9248        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 224, 224, 3)  867         conv2d_68[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,760,931\n",
      "Trainable params: 7,760,931\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 搭建U-Net\n",
    "def unet(input_size=(256, 256, 1), axis=3):\n",
    "    inputs = Input(input_size)\n",
    "    kernel_initializer = 'he_normal'\n",
    "    # kernel_initializer = 'zeros'\n",
    "    origin_filters = 32\n",
    "    conv1 = layers.Conv2D(origin_filters, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(inputs)\n",
    "    conv1 = layers.Conv2D(origin_filters, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = layers.Conv2D(origin_filters*2, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(pool1)\n",
    "    conv2 = layers.Conv2D(origin_filters*2, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = layers.Conv2D(origin_filters*4, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(pool2)\n",
    "    conv3 = layers.Conv2D(origin_filters*4, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = layers.Conv2D(origin_filters*8, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(pool3)\n",
    "    conv4 = layers.Conv2D(origin_filters*8, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv4)\n",
    "    drop4 = layers.Dropout(0.5)(conv4)\n",
    "\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    conv5 = layers.Conv2D(origin_filters*16, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(pool4)\n",
    "    conv5 = layers.Conv2D(origin_filters*16, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv5)\n",
    "    drop5 = layers.Dropout(0.5)(conv5)\n",
    "    up6 = layers.Conv2D(origin_filters * 8, 2, activation='relu', padding='same', kernel_initializer=kernel_initializer)(layers.UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = layers.concatenate([drop4, up6], axis=axis)\n",
    "\n",
    "    conv6 = layers.Conv2D(origin_filters*8, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(merge6)\n",
    "    conv6 = layers.Conv2D(origin_filters*8, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv6)\n",
    "\n",
    "    up7 = layers.Conv2D(origin_filters*4, 2, activation='relu', padding='same', kernel_initializer=kernel_initializer)(layers.UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = layers.concatenate([conv3, up7], axis=axis)\n",
    "    conv7 = layers.Conv2D(origin_filters*4, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(merge7)\n",
    "    conv7 = layers.Conv2D(origin_filters*4, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv7)\n",
    "\n",
    "    up8 = layers.Conv2D(origin_filters*2, 2, activation='relu', padding='same', kernel_initializer=kernel_initializer)(layers.UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = layers.concatenate([conv2, up8], axis=axis)\n",
    "    conv8 = layers.Conv2D(origin_filters*2, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(merge8)\n",
    "    conv8 = layers.Conv2D(origin_filters*2, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv8)\n",
    "\n",
    "    up9 = layers.Conv2D(origin_filters, 2, activation='relu', padding='same', kernel_initializer=kernel_initializer)(layers.UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = layers.concatenate([conv1, up9], axis=axis)\n",
    "    conv9 = layers.Conv2D(origin_filters, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(merge9)\n",
    "    conv9 = layers.Conv2D(origin_filters, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv9)\n",
    "    conv10 = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = unet(input_size=(224, 224, 3))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef4b628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置，命令行参数解析\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data-root', default=\"./dataset\", required=False, help='path to dataset')\n",
    "    parser.add_argument('--batch-size', type=int, default=8, help='input batch size')\n",
    "    parser.add_argument('--image-size', default=(224, 224, 3), help='the (height, width, channel) of the input image to network')\n",
    "    parser.add_argument('--niter', type=int, default=10, help='number of epochs to train for')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help='learning rate, default=0.0001')\n",
    "    # parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "    parser.add_argument('--model-save', default='./models/level1_model.h5', help='folder to output model checkpoints')\n",
    "    parser.add_argument('--model-path', default='./models/level1_model.h5', help='folder of model checkpoints to predict')\n",
    "    parser.add_argument('--outf', default=\"./test/test-level1\", required=False, help='path of predict output')\n",
    "    args = parser.parse_args(args=[])\n",
    "    try:\n",
    "        os.makedirs(args.outf)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e99b2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train_level1():\n",
    "    args = get_parser()  # 获取参数\n",
    "    train_data, train_label = load_image(args.data_root, \"train\")  # 训练数据集\n",
    "    val_data, val_label = load_image(args.data_root, 'val')        # 验证数据集\n",
    "    model = unet(input_size=args.image_size)  # 加载模型\n",
    "    model.compile(optimizer=optimizers.Adam(lr=args.lr), loss=dice_coefficient_loss,  # 设置优化器、损失函数和准确率评测标准\n",
    "                  metrics=['accuracy', dice_coefficient])\n",
    "    model_checkpoint = callbacks.ModelCheckpoint(args.model_save, monitor='loss', verbose=1,  # 保存模型\n",
    "                                                 save_best_only=True)\n",
    "    history = model.fit(train_data, train_label, batch_size=args.batch_size, epochs=args.niter,  # 训练模型\n",
    "                        callbacks=[model_checkpoint], validation_data=(val_data, val_label))\n",
    "    plot_history(history, args.outf)  # 绘制训练dice系数变化曲线和损失函数变化曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bead4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练dice系数变化曲线和损失函数变化曲线\n",
    "def plot_history(history, result_dir):\n",
    "    plt.plot([i+0.05 for i in history.history['dice_coefficient']], marker='.', color='r')\n",
    "    plt.plot([i+0.05 for i in history.history['val_dice_coefficient']], marker='*', color='b')\n",
    "    plt.title('model dice_coefficient')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('dice_coefficient')\n",
    "    plt.grid()\n",
    "    plt.ylim(0.6, 1.0)\n",
    "    plt.legend(['dice_coefficient', 'val_dice_coefficient'], loc='lower right')\n",
    "    plt.savefig(os.path.join(result_dir, 'model_dice_coefficient.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(history.history['loss'], marker='.', color='r')\n",
    "    plt.plot(history.history['val_loss'], marker='*', color='b')\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.grid()\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "    plt.savefig(os.path.join(result_dir, 'model_loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 将模型预测的标签转化为图像\n",
    "def tensorToimg(img):  # 0,85,170,255\n",
    "    row, column, channels = img.shape\n",
    "    for i in range(row):\n",
    "        for j in range(column):\n",
    "            if img[i, j, 0] >= 0.5:\n",
    "                img[i, j, 0] = 255\n",
    "            elif img[i, j, 1] >= 0.5:\n",
    "                img[i, j, 0] = 170\n",
    "            elif img[i, j, 2] >= 0.5:\n",
    "                img[i, j, 0] = 85\n",
    "            else:\n",
    "                img[i, j, 0] = 0\n",
    "    return img[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0d365f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型测试\n",
    "def predict_level1():\n",
    "    args = get_parser()  # 获取参数\n",
    "    test_img, test_label, test_name_list = load_image(args.data_root, \"test\", need_name_list=True)\n",
    "    model = load_model(args.model_path, custom_objects={'dice_coefficient': dice_coefficient,\n",
    "                                                        'dice_coefficient_loss': dice_coefficient_loss})\n",
    "    result = model.predict(test_img)\n",
    "    dc = dice_coff(test_label, result)\n",
    "    print(\"the dice coefficient is: \" + str(dc))\n",
    "    for i in range(result.shape[0]):\n",
    "        final_img = tensorToimg(result[i])\n",
    "        ori_img = test_img[i]\n",
    "        ori_gt = tensorToimg(test_label[i])\n",
    "\n",
    "        # 绘制结果图\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(ori_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.text(x=50, y=-15, s=\"ori_image\", ha='center', va='baseline',\n",
    "                 fontdict=dict(fontsize=10, color=\"green\", family='monospace', weight='bold'))\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(ori_gt, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.text(x=50, y=-15, s=\"ori_gt\", ha='center', va='baseline',\n",
    "                 fontdict=dict(fontsize=10, color=\"green\", family='monospace', weight='bold'))\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(final_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.text(x=50, y=-15, s=f\"predict\", ha='center', va='baseline',\n",
    "                 fontdict=dict(fontsize=10, color=\"green\", family='monospace', weight='bold'))\n",
    "        plt.text(x=50, y=255, s=f\"dice_coff: {dc:2f}\", ha='center', va='baseline',\n",
    "                 fontdict=dict(fontsize=10, color=\"white\", family='monospace', weight='bold'))\n",
    "        # plt.show()\n",
    "        plt.savefig(f\"{args.outf}/{test_name_list[i]}\")\n",
    "        print(f\"Save: {args.outf}/{test_name_list[i]}\")\n",
    "        plt.cla()\n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "520a9c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dice coefficient is: 0.900585604895704\n",
      "Save: ./test/test-level1/241.png\n",
      "Save: ./test/test-level1/242.png\n",
      "Save: ./test/test-level1/243.png\n",
      "Save: ./test/test-level1/244.png\n",
      "Save: ./test/test-level1/245.png\n",
      "Save: ./test/test-level1/246.png\n",
      "Save: ./test/test-level1/247.png\n",
      "Save: ./test/test-level1/248.png\n",
      "Save: ./test/test-level1/249.png\n",
      "Save: ./test/test-level1/250.png\n",
      "Save: ./test/test-level1/251.png\n",
      "Save: ./test/test-level1/252.png\n",
      "Save: ./test/test-level1/253.png\n",
      "Save: ./test/test-level1/254.png\n",
      "Save: ./test/test-level1/255.png\n",
      "Save: ./test/test-level1/256.png\n",
      "Save: ./test/test-level1/257.png\n",
      "Save: ./test/test-level1/258.png\n",
      "Save: ./test/test-level1/259.png\n",
      "Save: ./test/test-level1/260.png\n",
      "Save: ./test/test-level1/261.png\n",
      "Save: ./test/test-level1/262.png\n",
      "Save: ./test/test-level1/263.png\n",
      "Save: ./test/test-level1/264.png\n",
      "Save: ./test/test-level1/265.png\n",
      "Save: ./test/test-level1/266.png\n",
      "Save: ./test/test-level1/267.png\n",
      "Save: ./test/test-level1/268.png\n",
      "Save: ./test/test-level1/269.png\n",
      "Save: ./test/test-level1/270.png\n",
      "Save: ./test/test-level1/271.png\n",
      "Save: ./test/test-level1/272.png\n",
      "Save: ./test/test-level1/273.png\n",
      "Save: ./test/test-level1/274.png\n",
      "Save: ./test/test-level1/275.png\n",
      "Save: ./test/test-level1/276.png\n",
      "Save: ./test/test-level1/277.png\n",
      "Save: ./test/test-level1/278.png\n",
      "Save: ./test/test-level1/279.png\n",
      "Save: ./test/test-level1/280.png\n",
      "time: 31.253875494003296\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    s_t = time.time()\n",
    "    # train_level1()\n",
    "    predict_level1()\n",
    "    print(\"time:\", time.time()-s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b0d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6e910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2467b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
