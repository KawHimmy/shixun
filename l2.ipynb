{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0614a566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from keras.models import *\n",
    "from keras.models import load_model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, concatenate, BatchNormalization  \n",
    "from tensorflow.keras.models import Model  \n",
    "from tensorflow.keras.applications import VGG16  \n",
    "import os  \n",
    "import sys  \n",
    "  \n",
    "\n",
    "# 损失函数\n",
    "def dice_coefficient(y_true, y_pred, smooth=0.0000000001):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return 1-dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice_coff(label, predict):\n",
    "    return np.sum(2*label*predict)/(np.sum(label)+np.sum(predict))\n",
    "\n",
    "\n",
    "# 数据增强\n",
    "def image_process_enhanced(img):\n",
    "    img = cv2.equalizeHist(img)  # 像素直方图均衡\n",
    "    return img\n",
    "\n",
    "\n",
    "# 标签编码\n",
    "def label_to_code(label_img):\n",
    "    row, column, channels = label_img.shape\n",
    "    for i in range(row):\n",
    "        for j in range(column):\n",
    "            if label_img[i, j, 0] >= 0.75:\n",
    "                label_img[i, j, :] = [1, 0, 0]\n",
    "            elif (label_img[i, j, 0] < 0.75) & (label_img[i, j, 0] >= 0.5):\n",
    "                label_img[i, j, :] = [0, 1, 0]\n",
    "            elif (label_img[i, j, 0] < 0.5) & (label_img[i, j, 0] >= 0.25):\n",
    "                label_img[i, j, :] = [0, 0, 1]\n",
    "    return label_img\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "def load_image(root, data_type, size=None, need_name_list=False, need_enhanced=False):\n",
    "    image_path = os.path.join(root, data_type, \"image\")\n",
    "    label_path = os.path.join(root, data_type, \"label\")\n",
    "    print(image_path)\n",
    "\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    image_name_list = []\n",
    "    \n",
    "    k = 0  # 如果加载全部数据在平台中训练时间过长，或出现环境崩溃等问题，建议仅加载少量数据进行训练，可将此行代码注释去掉\n",
    "    for file in os.listdir(image_path):\n",
    "        image_file = os.path.join(image_path, file)\n",
    "        label_file_name = file.split(\".\")[0]+\".png\"\n",
    "        label_file = os.path.join(label_path, label_file_name)\n",
    "        if need_name_list is True:\n",
    "            image_name_list.append(file)\n",
    "        img = cv2.imread(image_file)\n",
    "        label = cv2.imread(label_file)\n",
    "        if size is not None:\n",
    "            row, column, channel = size\n",
    "            img = cv2.resize(img, (column, row, channel))\n",
    "            label = cv2.resize(label, (column, row, channel))\n",
    "        # 对图像进行增强\n",
    "        if need_enhanced is True:\n",
    "            img = image_process_enhanced(img)\n",
    "\n",
    "        img = img / 255\n",
    "        label = label / 255\n",
    "        image_list.append(img)\n",
    "        label = label_to_code(label)  # 对标签进行编码\n",
    "        label_list.append(label)\n",
    "        \n",
    "        # 如果加载全部数据在平台中训练时间过长，或出现环境崩溃等问题，建议仅加载少量数据进行训练，可将以下几行代码注释去掉\n",
    "        k += 1\n",
    "        if k>39:\n",
    "            break\n",
    "            \n",
    "    if need_name_list is True:\n",
    "        return np.array(image_list), np.array(label_list), image_name_list\n",
    "    else:\n",
    "        return np.array(image_list), np.array(label_list)\n",
    "\n",
    "\n",
    "# 将模型预测的标签转化为图像\n",
    "def tensorToimg(img):  # 0,85,170,255\n",
    "    row, column, channels = img.shape\n",
    "    for i in range(row):\n",
    "        for j in range(column):\n",
    "            if img[i, j, 0] >= 0.5:\n",
    "                img[i, j, 0] = 255\n",
    "            elif img[i, j, 1] >= 0.5:\n",
    "                img[i, j, 0] = 170\n",
    "            elif img[i, j, 2] >= 0.5:\n",
    "                img[i, j, 0] = 85\n",
    "            else:\n",
    "                img[i, j, 0] = 0\n",
    "    return img[:, :, 0]\n",
    "\n",
    "\n",
    "# 绘制训练dice系数变化曲线和损失函数变化曲线\n",
    "def plot_history(history, result_dir):\n",
    "    plt.plot([i+0.05 for i in history.history['dice_coefficient']], marker='.', color='r')\n",
    "    plt.plot([i+0.05 for i in history.history['val_dice_coefficient']], marker='*', color='b')\n",
    "    plt.title('model dice_coefficient')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('dice_coefficient')\n",
    "    plt.grid()\n",
    "    plt.ylim(0.6, 1.0)\n",
    "    plt.legend(['dice_coefficient', 'val_dice_coefficient'], loc='lower right')\n",
    "    plt.savefig(os.path.join(result_dir, 'model_dice_coefficient.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(history.history['loss'], marker='.', color='r')\n",
    "    plt.plot(history.history['val_loss'], marker='*', color='b')\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.grid()\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "    plt.savefig(os.path.join(result_dir, 'model_loss.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "def VGG16_unet_model(input_size=(224, 224, 3), use_batchnorm=False, if_transfer=False, if_local=True):\n",
    "    axis = 3\n",
    "    kernel_initializer = 'he_normal'\n",
    "    origin_filters=32\n",
    "    weights = None\n",
    "    model_path = os.path.join(sys.path[0], 'models', 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    print(model_path)\n",
    "    if if_transfer is True:\n",
    "        if if_local is True:\n",
    "            weights = model_path\n",
    "        else:\n",
    "            weights = 'imagenet'\n",
    "    vgg16 = VGG16(include_top=False, weights=weights, input_shape=input_size)\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False  # 冻结VGG16参数\n",
    "        # layer.trainable = True\n",
    "\n",
    "    # 跨域特征提取层  \n",
    "    # input_img = Input(shape=input_size)  \n",
    "    # cross_domain_features = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer)(input_img)  \n",
    "    # cross_domain_features = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer)(cross_domain_features)\n",
    "    # # 假设cross_domain_features是你的输入特征图  \n",
    "    # reduced_channels = Conv2D(3, (1, 1), activation='relu')(cross_domain_features)  \n",
    "    # vgg16_input = VGG16(include_top=False, weights='imagenet', input_tensor=reduced_channels)\n",
    "    output = vgg16.layers[17].output\n",
    "    # output = vgg16.layers[17].output\n",
    "    print(output.shape)\n",
    "    up6 = layers.Conv2D(origin_filters*8, 2, activation='relu', padding='same', kernel_initializer=kernel_initializer)(\n",
    "        layers.UpSampling2D(size=(2, 2))(output))\n",
    "    merge6 = layers.concatenate([vgg16.layers[13].output, up6], axis=axis)\n",
    "    conv6 = layers.Conv2D(origin_filters*8, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(merge6)\n",
    "    conv6 = layers.Conv2D(origin_filters*8, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv6)\n",
    "    if use_batchnorm is True:\n",
    "        conv6 = layers.BatchNormalization()(conv6)\n",
    "    up7 = layers.Conv2D(origin_filters*4, 2, activation='relu', padding='same', kernel_initializer=kernel_initializer)(\n",
    "        layers.UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = layers.concatenate([vgg16.layers[9].output, up7], axis=axis)\n",
    "    conv7 = layers.Conv2D(origin_filters*4, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(merge7)\n",
    "    conv7 = layers.Conv2D(origin_filters*4, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv7)\n",
    "    if use_batchnorm is True:\n",
    "        conv7 = layers.BatchNormalization()(conv7)\n",
    "    up8 = layers.Conv2D(origin_filters*2, 2, activation='relu', padding='same', kernel_initializer=kernel_initializer)(\n",
    "        layers.UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = layers.concatenate([vgg16.layers[5].output, up8], axis=axis)\n",
    "    conv8 = layers.Conv2D(origin_filters*2, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(merge8)\n",
    "    conv8 = layers.Conv2D(origin_filters*2, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv8)\n",
    "    if use_batchnorm is True:\n",
    "        conv8 = layers.BatchNormalization()(conv8)\n",
    "    up9 = layers.Conv2D(origin_filters, 2, activation='relu', padding='same', kernel_initializer=kernel_initializer)(\n",
    "        layers.UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = layers.concatenate([vgg16.layers[2].output, up9], axis=axis)\n",
    "    conv9 = layers.Conv2D(origin_filters, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(merge9)\n",
    "    conv9 = layers.Conv2D(origin_filters, 3, activation='relu', padding='same', kernel_initializer=kernel_initializer)(conv9)\n",
    "    if use_batchnorm is True:\n",
    "        conv9 = layers.BatchNormalization()(conv9)\n",
    "    conv10 = layers.Conv2D(3, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=vgg16.input, outputs=conv10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244004a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置，命令行参数解析\n",
    "# 可自行调整相关超参数，此处为尽快演示，niter设置为1，即epoch设置为1，仅训练1轮\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data-root', default=\"./dataset\", required=False, help='path to dataset')\n",
    "    parser.add_argument('--img_enhanced', default=False, help='image enhancement')\n",
    "    parser.add_argument('--batch-size', type=int, default=8, help='input batch size')\n",
    "    parser.add_argument('--image-size', default=(224, 224, 3), help='the (height, width, channel) of the input image to network')\n",
    "    parser.add_argument('--niter', type=int, default=200, help='number of epochs to train for')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help='learning rate, default=0.0001')\n",
    "    parser.add_argument('--model-save', default='./models/level3_model.h5', help='folder to output model checkpoints')\n",
    "    parser.add_argument('--model-path', default='./models/level3_model.h5', help='folder of model checkpoints to predict')\n",
    "    parser.add_argument('--outf', default=\"./test/test-level3\", required=False, help='path of predict output')\n",
    "    args = parser.parse_args(args=[])\n",
    "    try:\n",
    "        os.makedirs(args.outf)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "# 模型训练\n",
    "def train_level3():\n",
    "    args = get_parser()  # 获取参数\n",
    "    train, train_label = load_image(args.data_root, \"train\", need_enhanced=args.img_enhanced)  # dataset为实际使用数据\n",
    "    val, val_label = load_image(args.data_root, 'val', need_enhanced=args.img_enhanced)\n",
    "    model = VGG16_unet_model(input_size=args.image_size)\n",
    "    model.compile(optimizer=optimizers.Adam(lr=args.lr), loss=dice_coefficient_loss,\n",
    "                  metrics=[dice_coefficient])  # loss=dice_coef_loss_vgg16\n",
    "    model_checkpoint = callbacks.ModelCheckpoint(args.model_path, monitor='loss', verbose=1, save_best_only=True)\n",
    "    history = model.fit(train, train_label, batch_size=args.batch_size, epochs=args.niter, callbacks=[model_checkpoint],\n",
    "                        validation_data=(val, val_label))\n",
    "    plot_history(history, args.outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd22e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\train\\image\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: './dataset\\\\train\\\\image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m s_t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_level3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m, in \u001b[0;36mtrain_level3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_level3\u001b[39m():\n\u001b[0;32m     25\u001b[0m     args \u001b[38;5;241m=\u001b[39m get_parser()  \u001b[38;5;66;03m# 获取参数\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     train, train_label \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_enhanced\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_enhanced\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# dataset为实际使用数据\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     val, val_label \u001b[38;5;241m=\u001b[39m load_image(args\u001b[38;5;241m.\u001b[39mdata_root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, need_enhanced\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mimg_enhanced)\n\u001b[0;32m     28\u001b[0m     model \u001b[38;5;241m=\u001b[39m VGG16_unet_model(input_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mimage_size)\n",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(root, data_type, size, need_name_list, need_enhanced)\u001b[0m\n\u001b[0;32m     68\u001b[0m image_name_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     70\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# 如果加载全部数据在平台中训练时间过长，或出现环境崩溃等问题，建议仅加载少量数据进行训练，可将此行代码注释去掉\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     72\u001b[0m     image_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_path, file)\n\u001b[0;32m     73\u001b[0m     label_file_name \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_gt.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: './dataset\\\\train\\\\image'"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "train_level3()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
